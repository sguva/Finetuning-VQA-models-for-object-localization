{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the COCO 2017 dataset from https://cocodataset.org/\n",
    "\n",
    "Also, note that the non-LoRA finetuned versions of BLIP2 models are around 15GB each as in case of model fintuned using LoRA only the adapter weights are stored which is smaller in size when compared to the actual model weights. When we load the finetuned model, we first load the actual model (which is loaded from HF cache if already exists otherwise it'll download from the web and will cache it.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Set paths to dataset and saving temporary files.**\n",
    "\n",
    "Set CUDA_VISIBLE_DEVICES env variable as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%env DATASET_PATH=/NLP - Project/COCO 2017 NLP/\n",
    "%env SAVE_DIR=/nlp_project/\n",
    "%env CUDA_VISIBLE_DEVICES=0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Generate training and validation data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "___________Working on train data_________________\n",
      "[{'image_id': 558840, 'bbox': [199.84, 200.46, 77.71, 70.88], 'category_id': 58}, {'image_id': 200365, 'bbox': [234.22, 317.11, 149.39, 38.55], 'category_id': 58}, {'image_id': 200365, 'bbox': [239.48, 347.87, 160.0, 57.81], 'category_id': 58}, {'image_id': 200365, 'bbox': [296.65, 388.33, 1.03, 0.0], 'category_id': 58}, {'image_id': 200365, 'bbox': [251.87, 333.42, 125.94, 22.71], 'category_id': 58}, {'image_id': 495357, 'bbox': [337.02, 244.46, 66.47, 66.75], 'category_id': 18}, {'image_id': 116061, 'bbox': [213.81, 192.39, 53.94, 70.28], 'category_id': 18}, {'image_id': 16164, 'bbox': [324.66, 247.92, 250.87, 181.02], 'category_id': 18}, {'image_id': 205350, 'bbox': [260.18, 252.76, 67.91, 53.3], 'category_id': 18}, {'image_id': 74, 'bbox': [61.87, 276.25, 296.42, 103.18], 'category_id': 18}]\n",
      "Time taken:  0.31240365902582806  minutes.\n",
      "Written 860001 annotations to file\n",
      "Done. Time taken:  0.4595642566680908  minutes.\n",
      "Written 201358 annotations to file\n",
      "Done. Time taken:  0.09404139121373495  minutes.\n",
      "Done. Time taken:  0.27907621463139853  minutes.\n",
      "Done. Time taken:  0.5838054339090983  minutes.\n",
      "558840 [('hot dog', 'middleCenter'), ('cup', 'middleLeft'), ('dining table', 'bottomLeft')]\n",
      "495357 [('dog', 'middleCenter'), ('motorcycle', 'middleCenter')]\n",
      "116061 [('dog', 'middleCenter'), ('handbag', 'middleLeft'), ('bottle', 'middleCenter')]\n",
      "16164 [('dog', 'bottomRight'), ('toilet', 'topLeft')]\n",
      "95899\n",
      "1302241 questions and answers generated.\n",
      "\n",
      "Questions and answers saved to /scratch/efk7cz/nlp_project/data_generation/generated_questions_and_answers_train.csv.\n",
      "\n",
      "___________Working on val data_________________\n",
      "[{'image_id': 289343, 'bbox': [473.07, 395.93, 38.65, 28.67], 'category_id': 18}, {'image_id': 61471, 'bbox': [272.1, 200.23, 151.97, 279.77], 'category_id': 18}, {'image_id': 472375, 'bbox': [124.71, 196.18, 372.85, 356.81], 'category_id': 18}, {'image_id': 520301, 'bbox': [112.71, 154.82, 367.29, 479.35], 'category_id': 18}, {'image_id': 579321, 'bbox': [200.61, 89.65, 400.22, 251.02], 'category_id': 18}, {'image_id': 494869, 'bbox': [0.0, 421.09, 154.53, 208.61], 'category_id': 18}, {'image_id': 554002, 'bbox': [427.58, 77.87, 188.88, 285.91], 'category_id': 18}, {'image_id': 78823, 'bbox': [197.97, 117.22, 170.45, 222.07], 'category_id': 18}, {'image_id': 419974, 'bbox': [61.68, 389.34, 130.77, 138.47], 'category_id': 18}, {'image_id': 404484, 'bbox': [86.93, 90.76, 82.5, 74.54], 'category_id': 18}]\n",
      "Time taken:  0.008570337295532226  minutes.\n",
      "Written 36781 annotations to file\n",
      "Done. Time taken:  0.013619458675384522  minutes.\n",
      "Written 8548 annotations to file\n",
      "Done. Time taken:  0.006101087729136149  minutes.\n",
      "Done. Time taken:  0.006168095270792643  minutes.\n",
      "Done. Time taken:  0.013556166489919027  minutes.\n",
      "289343 [('dog', 'middleRight'), ('person', 'middleCenter'), ('bench', 'bottomLeft'), ('bicycle', 'middleCenter')]\n",
      "61471 [('dog', 'bottomCenter'), ('bottle', 'topLeft'), ('toilet', 'topCenter')]\n",
      "472375 [('dog', 'middleCenter'), ('motorcycle', 'middleCenter')]\n",
      "520301 [('dog', 'middleCenter')]\n",
      "4109\n",
      "54874 questions and answers generated.\n",
      "\n",
      "Questions and answers saved to /scratch/efk7cz/nlp_project/data_generation/generated_questions_and_answers_val.csv.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!python gen_data_from_COCO.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Finetune the classification model.**\n",
    "\n",
    "Inputs: Image + object name (as text) | Output: Classification label\n",
    "\n",
    "We'll be using the ViltForQuestionAnswering model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/scratch/efk7cz/anaconda3/envs/nlp_project/lib/python3.10/site-packages/transformers/utils/hub.py:123: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n",
      "  warnings.warn(\n",
      "Available processors list: {64}\n",
      "All required directories exist of COCO dataset.\n",
      "Loading train data dictionary............\n",
      "Len of dic: 171\n",
      "Encoding data: 100%|█████████████████████████| 171/171 [00:01<00:00, 130.27it/s]\n",
      "Saving data_encoded to disk.... at /scratch/efk7cz/nlp_project/data_generation/saved_as_pth/classification/classification_train_-1.pth\n",
      "Done saving!\n",
      "Some weights of ViltForQuestionAnswering were not initialized from the model checkpoint at dandelin/vilt-b32-mlm and are newly initialized: ['classifier.1.bias', 'classifier.0.weight', 'classifier.1.weight', 'classifier.0.bias', 'classifier.3.weight', 'classifier.3.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "\n",
      "Training for 2 epochs.............\n",
      "Epoch 0: 100%|█████████████████████████| 6/6 [00:03<00:00,  1.51it/s, loss=5.56]\n",
      "Epoch 0, Loss: 6.0210206508636475\n",
      "Epoch 1: 100%|█████████████████████████| 6/6 [00:01<00:00,  3.69it/s, loss=4.61]\n",
      "Epoch 1, Loss: 4.95771853129069\n",
      "\n",
      " Saved the training verbose and training loss at /scratch/efk7cz/nlp_project/classification\n",
      "\n",
      "Saved model to disk after final epoch !\n",
      "Created HF pipeline and saved it as well.\n",
      "object_name: microwave\n",
      "prection: [{'score': 0.38649290800094604, 'answer': 'middleLeft'}]\n",
      "Actual location: middleCenter\n",
      "Total time taken: 0:00:41.511006\n"
     ]
    }
   ],
   "source": [
    "!python classification_train.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load the saved classification model to run it on validation data and save the results to csv file.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/scratch/efk7cz/anaconda3/envs/nlp_project/lib/python3.10/site-packages/transformers/utils/hub.py:123: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n",
      "  warnings.warn(\n",
      "Available processors list: {64}\n",
      "All required directories exist of COCO dataset.\n",
      "Loading dictionary............\n",
      "Len of dic: 19\n",
      "Dataset({\n",
      "    features: ['row_id', 'image_id', 'image_path', 'positionName', 'categoryName'],\n",
      "    num_rows: 19\n",
      "})\n",
      "Map: 100%|███████████████████████████████| 19/19 [00:01<00:00, 13.18 examples/s]\n",
      "Processed dataset:\n",
      "Dataset({\n",
      "    features: ['image', 'question', 'answer'],\n",
      "    num_rows: 19\n",
      "})\n",
      "Running Inference::  32%|███████▌                | 6/19 [00:00<00:01,  7.82it/s]/scratch/efk7cz/anaconda3/envs/nlp_project/lib/python3.10/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "Running Inference:: 100%|███████████████████████| 19/19 [00:01<00:00, 14.66it/s]\n",
      "Validation Accuracy: 0.15789473684210525\n",
      "---------Saved the results at classification_results.csv-----------\n",
      "Total time taken: 0:00:09.051300\n"
     ]
    }
   ],
   "source": [
    "!python classification_val.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now moving onto Question-Answering model which generates text.**\n",
    "\n",
    "Inputs: Image + Question (text) | Output: Generated Answer (text)\n",
    "\n",
    "We'll be finetuning the BLIP2 model using LoRA.\n",
    "\n",
    "The model itself take around 15GB on GPU, so make sure the GPU you are using has atleast 32GB of memory to run the training code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/scratch/efk7cz/anaconda3/envs/nlp_project/lib/python3.10/site-packages/transformers/utils/hub.py:123: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n",
      "  warnings.warn(\n",
      "Available processors list: {64}\n",
      "All required directories exist of COCO dataset.\n",
      "Loading train data dictionary............\n",
      "Len of dic: 1186\n",
      "Encoding image data: 100%|████████████████| 1186/1186 [00:01<00:00, 1175.21it/s]\n",
      "Saving data_encoded to disk.... at /scratch/efk7cz/nlp_project/data_generation/saved_as_pth/answer_generation/answer_generation_train_-1.pth\n",
      "Done saving!\n",
      "\n",
      " Loading the model..........\n",
      "Downloading shards: 100%|███████████████████████| 8/8 [00:00<00:00, 3219.89it/s]\n",
      "Loading checkpoint shards: 100%|██████████████████| 8/8 [00:03<00:00,  2.01it/s]\n",
      "trainable params: 83,886,080 || all params: 3,828,566,016 || trainable%: 2.191057425924767\n",
      "\n",
      "Training for 2 epochs.........\n",
      "Epoch 0: 100%|██████████████████████| 38/38 [00:47<00:00,  1.25s/it, loss=0.764]\n",
      "Epoch 0, Loss: 2.523900082236842\n",
      "Epoch 1: 100%|███████████████████████| 38/38 [00:45<00:00,  1.19s/it, loss=0.58]\n",
      "Epoch 1, Loss: 0.5673057154605263\n",
      "Figure(1000x500)\n",
      "Saved model to disk after final epoch !!\n",
      "\n",
      "Inference check on sample idx:5\n",
      "Question: Locate the the bicycle within the image. Answer:\n",
      "Generated answer: The bicycle is located at the middleCenter of the image.\n",
      "Actual answer:    The bicycle is located at the middleLeft of the image.\n",
      "\n",
      "Total time taken: 0:02:58.643559\n"
     ]
    }
   ],
   "source": [
    "!python answer_generation_train.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load the saved QA model to run it on validation data and save the results to csv file.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/scratch/efk7cz/anaconda3/envs/nlp_project/lib/python3.10/site-packages/transformers/utils/hub.py:123: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n",
      "  warnings.warn(\n",
      "Available processors list: {64}\n",
      "All required directories exist of COCO dataset.\n",
      "Loading val data dictionary............\n",
      "Len of dic: 112\n",
      "Encoding image data: 100%|██████████████████| 112/112 [00:00<00:00, 1012.96it/s]\n",
      "Saving data_encoded to disk.... at /scratch/efk7cz/nlp_project/data_generation/saved_as_pth/answer_generation/answer_generation_val_-1.pth\n",
      "Done saving!\n",
      "\n",
      " Loading the model..........\n",
      "Downloading shards: 100%|███████████████████████| 8/8 [00:00<00:00, 1838.70it/s]\n",
      "Loading checkpoint shards: 100%|██████████████████| 8/8 [00:06<00:00,  1.19it/s]\n",
      "Running Inference:: 100%|█████████████████████| 112/112 [02:58<00:00,  1.59s/it]\n",
      "---------Saved the results at answer_generation_results.csv-----------\n",
      "Total time taken: 0:03:19.094545\n"
     ]
    }
   ],
   "source": [
    "!python answer_generation_val.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**For evaluation on the generated results, please check the intrinsic_evaluation.ipynb and extrinsic_evaluation.ipynb notebooks.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "****Delete the SAVE_DIR and its contents****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf $SAVE_DIR/*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove the initially set environment variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: -u=DATASET_PATH\n",
      "env: -u=SAVE_DIR\n"
     ]
    }
   ],
   "source": [
    "# Remove environment variables.\n",
    "%env -u DATASET_PATH\n",
    "%env -u SAVE_DIR"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
